# Experiments in prompting

These were done using the chat.openai.com chat interface. 
I've also used the API via Python to access it programmatically. Demo of that is elsewhere.
The API is better for batch-testing a prompt to make sure it's robust. (It may not be on its own. 
Multiple steps may be needed.)

ChatGPT is also useful for answering coding questions, though it's worth checking. 
When I asked about markdown for github, it told me that I could initialize the file with ```markdown
and that failed.

## Data Scientist job post that's friendly to people with imposter syndrome

It really really struggled with this. The default data scientist ad must be very common.

[Friendly Data Scientist Job Post](https://chat.openai.com/share/99aa12f4-98c9-429f-b7dc-9abe2221585e)

## Healthcare: does patient history get attributed correctly?

Yes. A colleague in the HC industry had trouble with family history being attributed to patient, but chatgpt seems 
able to sort it out, even when pressed. This is a pretty short text, though. A longer history or set of notes might stump it. 

[Processing patient notes](https://chat.openai.com/share/ecaf82cf-1042-498d-99d5-b8a48cf97506)

## Fooled into making a buzzword-filled ad
If asked explicitly to add buzzwords it doesn't want to, but it doesn't resist too hard.

[All the buzzwords](https://chat.openai.com/share/f563eb68-15f0-4175-9436-f03402423d22)

## Storytelling and summarizing

The story is a good demonstration that "show, don't tell" is more compelling than the opposite. 
The summary is reasonable. 

[Crappy story & reasonable summary](https://chat.openai.com/share/5068d5d3-b091-4521-9676-e7c2f92b4a39)

